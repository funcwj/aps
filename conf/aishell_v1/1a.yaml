nnet: "asr@att"

nnet_conf:
  input_size: 80
  enc_type: "concat"
  enc_proj: 512
  enc_kwargs:
    conv2d:
      out_features: -1
      channel: 48
      num_layers: 3
      stride: 2
      padding: 1
      kernel_size: 3
    pytorch_rnn:
      rnn: "lstm"
      num_layers: 3
      bidirectional: true
      dropout: 0.2
      hidden: 320
  dec_dim: 512
  dec_kwargs:
    dec_rnn: "lstm"
    rnn_layers: 2
    rnn_hidden: 512
    rnn_dropout: 0.2
    emb_dropout: 0.3
    input_feeding: true
  att_type: "ctx"
  att_kwargs:
    att_dim: 512

task: "asr@ctc_xent"

task_conf:
  reduction: batchmean
  lsm_factor: 0.1
  ctc_weight: 0.3

asr_transform:
  feats: "perturb-fbank-log-cmvn-aug"
  frame_len: 400
  frame_hop: 160
  window: "hamm"
  round_pow_of_two: true
  sr: 16000
  pre_emphasis: 0.97
  num_mels: 80
  norm_mean: true
  norm_var: true
  aug_prob: 0.5
  aug_mask_zero: false
  aug_freq_args: [30, 1]
  aug_time_args: [80, 1]

trainer_conf:
  optimizer: "adam"
  optimizer_kwargs:
    lr: 1.0e-3
    weight_decay: 1.0e-5
  lr_scheduler: "warmup_exp_decay_lr"
  lr_scheduler_period: "step"
  lr_scheduler_kwargs:
    time_stamps: [800, 40000, 100000]
    peak_lr: 1.0e-3
    stop_lr: 1.0e-7
  ss_scheduler: "linear"
  ss_scheduler_kwargs:
    ssr: 0.2
    epochs: [10, 26]
    update_interval: 4
  no_impr: 10
  no_impr_thres: 0.01
  clip_gradient: 5
  report_metrics: ["loss", "accu", "@ctc"]
  stop_criterion: "accu"

data_conf:
  fmt: "am@raw"
  loader:
    max_dur: 30 # (s)
    min_dur: 0.4 # (s)
    adapt_dur: 10 # (s)
    max_token_num: 400
    adapt_token_num: 150
  train:
    wav_scp: "data/aishell_v1/train/wav.scp"
    utt2dur: "data/aishell_v1/train/utt2dur"
    text: "data/aishell_v1/train/text"
  valid:
    wav_scp: "data/aishell_v1/dev/wav.scp"
    utt2dur: "data/aishell_v1/dev/utt2dur"
    text: "data/aishell_v1/dev/text"
